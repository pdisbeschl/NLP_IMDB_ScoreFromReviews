{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting user ratings based on corresponding text reviews</h1>  \n",
    "<h6>Paul Disbeschl and Timothy Smeets</h6>\n",
    "<h6>Department of Data Science and Knowledge Engineering, Maastricht University</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies pre-processing to the SAR14 dataset of Nguyen et al. and showcases the effectiveness of different techniques used to predict the sentiments of film reviews.\n",
    "<b><i> DISCLAIMER: As the training and test data split is partially randomized, keep in mind that running the code might result in small deviations from the accuracy scores given.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136516</th>\n",
       "      <td>I love the movie Rent !!!! . I love the movie...</td>\n",
       "      <td>,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88514</th>\n",
       "      <td>Breathtaking visuals . If they gave Oscars fo...</td>\n",
       "      <td>,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154144</th>\n",
       "      <td>A Breath of Fresh Air . Some of you are takin...</td>\n",
       "      <td>,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53637</th>\n",
       "      <td>Fight Movie Clich s in Spaaaaaaaaaaaaace . . ...</td>\n",
       "      <td>,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83508</th>\n",
       "      <td>Just crap . This movie is a total crap , ther...</td>\n",
       "      <td>,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review score\n",
       "136516   I love the movie Rent !!!! . I love the movie...   ,10\n",
       "88514    Breathtaking visuals . If they gave Oscars fo...    ,8\n",
       "154144   A Breath of Fresh Air . Some of you are takin...   ,10\n",
       "53637    Fight Movie Clich s in Spaaaaaaaaaaaaace . . ...    ,4\n",
       "83508    Just crap . This movie is a total crap , ther...    ,2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "from nltk.corpus import sentiwordnet as sent\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.model_selection import train_test_split #to split data, also for stratification\n",
    "import random #also to split our shit\n",
    "\n",
    "df = pd.read_csv('data/sar14.txt', sep=\" \", header=None, names=[\"review\", \"score\"])\n",
    "df.head()\n",
    "\n",
    "reviews = df['review']\n",
    "scores = df['score']\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(reviews, scores, stratify=scores, test_size=0.2)\n",
    "#This applies stratification to the dataset and splits it up equally according to score. X = review col, Y = score col\n",
    "\n",
    "train_x = pd.DataFrame({'review':x_tr})\n",
    "train_y = pd.DataFrame({'score':y_tr})\n",
    "train_data = pd.concat([train_x,train_y], axis=1) #train_data is the training data, 80% of the text and scores\n",
    "train_data.head()\n",
    "\n",
    "test_x = pd.DataFrame({'review':x_te})\n",
    "test_y = pd.DataFrame({'score':y_te})\n",
    "data = pd.concat([test_x,test_y], axis=1) #data is the testing data, 20% of the text and scores from the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b> Pre-processing </b>  </h1>\n",
    "\n",
    "In order to run experiments on our dataframe, it needs to be cleaned first. Our approach for this is to use regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method is used to clean the dataset using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r\"-RRB-\",'',text)\n",
    "    text = re.sub(r\"-LRB-\",'',text)\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the method above to clean both the training and the test data. This is more for visual purposes so you can see what the cleaned text looks like, as later on we use the clean_text method within the vectorizer functions provided by the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136516</th>\n",
       "      <td>i love the movie rent        i love the movie ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88514</th>\n",
       "      <td>breathtaking visuals   if they gave oscars for...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154144</th>\n",
       "      <td>a breath of fresh air   some of you are taking...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53637</th>\n",
       "      <td>fight movie clich s in spaaaaaaaaaaaaace     h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83508</th>\n",
       "      <td>just crap   this movie is a total crap   there...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review score\n",
       "136516  i love the movie rent        i love the movie ...    10\n",
       "88514   breathtaking visuals   if they gave oscars for...     8\n",
       "154144  a breath of fresh air   some of you are taking...    10\n",
       "53637   fight movie clich s in spaaaaaaaaaaaaace     h...     4\n",
       "83508   just crap   this movie is a total crap   there...     2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_data.index:\n",
    "    train_data.at[i, 'review'] = clean_text(train_data.at[i, 'review'])\n",
    "    train_data.at[i, 'score'] = clean_text(train_data.at[i,'score'])\n",
    "    \n",
    "for i in data.index:\n",
    "    data.at[i, 'review'] = clean_text(data.at[i, 'review'])\n",
    "    data.at[i, 'score'] = clean_text(data.at[i,'score'])\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the data on just positive/negative sentiment, we need to assign sentiment to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>binarysentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14066</th>\n",
       "      <td>more stupid jerry   once again jerry stinks up...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57123</th>\n",
       "      <td>nice little drama   good performances from the...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53460</th>\n",
       "      <td>what an amazing love story   i adored this fil...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174391</th>\n",
       "      <td>great     i was told about the 4400 after the ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54693</th>\n",
       "      <td>pan is back   purportedly steven spielberg is ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  score  \\\n",
       "14066   more stupid jerry   once again jerry stinks up...      1   \n",
       "57123   nice little drama   good performances from the...      7   \n",
       "53460   what an amazing love story   i adored this fil...     10   \n",
       "174391  great     i was told about the 4400 after the ...      7   \n",
       "54693   pan is back   purportedly steven spielberg is ...      9   \n",
       "\n",
       "        binarysentiment  \n",
       "14066               0.0  \n",
       "57123               0.0  \n",
       "53460               1.0  \n",
       "174391              0.0  \n",
       "54693               1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.score = pd.to_numeric(train_data.score, errors = 'coerce')\n",
    "data.score = pd.to_numeric(data.score, errors = 'coerce')\n",
    "\n",
    "for i in train_data.index:\n",
    "    if train_data.at[i,'score']> 7:\n",
    "        train_data.at[i,'binarysentiment'] = 1\n",
    "    else:\n",
    "        train_data.at[i,'binarysentiment'] = 0\n",
    "    \n",
    "    \n",
    "for j in data.index:\n",
    "    if data.at[j,'score']> 7:\n",
    "        data.at[j,'binarysentiment'] = 1\n",
    "    else:\n",
    "        data.at[j,'binarysentiment'] = 0\n",
    "        \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do research on multi-class classification, we can use the \"score\" column. Later on, we also want to lower the amount of classes, for which we have to create a new column where a value is assigned corresponding to the \"score\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>binarysentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14066</th>\n",
       "      <td>more stupid jerry   once again jerry stinks up...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57123</th>\n",
       "      <td>nice little drama   good performances from the...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53460</th>\n",
       "      <td>what an amazing love story   i adored this fil...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174391</th>\n",
       "      <td>great     i was told about the 4400 after the ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54693</th>\n",
       "      <td>pan is back   purportedly steven spielberg is ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  score  \\\n",
       "14066   more stupid jerry   once again jerry stinks up...      1   \n",
       "57123   nice little drama   good performances from the...      7   \n",
       "53460   what an amazing love story   i adored this fil...     10   \n",
       "174391  great     i was told about the 4400 after the ...      7   \n",
       "54693   pan is back   purportedly steven spielberg is ...      9   \n",
       "\n",
       "        binarysentiment  sentiment  \n",
       "14066               0.0        1.0  \n",
       "57123               0.0        3.0  \n",
       "53460               1.0        4.0  \n",
       "174391              0.0        3.0  \n",
       "54693               1.0        4.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign sentiment with classes\n",
    "# 1-2 = 1, 3-4 = 2, 7-8 = 3, 9-10 = 4\n",
    "\n",
    "train_data.score = pd.to_numeric(train_data.score, errors = 'coerce')\n",
    "data.score = pd.to_numeric(data.score, errors = 'coerce')\n",
    "\n",
    "for i in train_data.index:\n",
    "    if train_data.at[i,'score']<= 2:\n",
    "        train_data.at[i,'sentiment'] = 1\n",
    "    elif train_data.at[i,'score']== 4 or train_data.at[i,'score']== 3:\n",
    "        train_data.at[i,'sentiment'] = 2\n",
    "    elif train_data.at[i,'score']== 7 or train_data.at[i,'score']== 8:\n",
    "        train_data.at[i,'sentiment'] = 3\n",
    "    elif train_data.at[i,'score']== 9 or train_data.at[i,'score']== 10:\n",
    "        train_data.at[i,'sentiment'] = 4\n",
    "    else:\n",
    "        train_data.at[i,'sentiment'] = 0\n",
    "\n",
    "    \n",
    "for j in data.index:\n",
    "    if data.at[j,'score']<= 2:\n",
    "        data.at[j,'sentiment'] = 1\n",
    "    elif data.at[j,'score']== 4 or data.at[j,'score']== 3:\n",
    "        data.at[j,'sentiment'] = 2\n",
    "    elif data.at[j,'score']== 7 or data.at[j,'score']== 8:\n",
    "        data.at[j,'sentiment'] = 3\n",
    "    elif data.at[j,'score']== 9 or data.at[j,'score']== 10:\n",
    "        data.at[j,'sentiment'] = 4\n",
    "    else:\n",
    "        data.at[j,'sentiment'] = 0\n",
    "        \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Tests on binary sentiment (positive/negative)  </b>  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and without N-grams </b>\n",
    "\n",
    "77.72% accuracy on binary sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothy\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Transform each review into a vector of word counts\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "                             \n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "# Training a Linear Support Vector Machine model\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"binarysentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "# Calculating the accuracy\n",
    "acc = accuracy_score(data[\"binarysentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and with N-grams </b>\n",
    "\n",
    "84.26% accuracy on binary sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.26\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"binarysentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"binarysentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and without N-grams </b>\n",
    "\n",
    "Score of 82.11% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"binarysentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"binarysentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and with N-grams </b>\n",
    "\n",
    "Score of 82.11% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"binarysentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"binarysentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes without tf-idf and without N-grams </b>\n",
    "\n",
    "83.01% accuracy on binary sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.30\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "                             \n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=6)\n",
    "clf.fit(training_features,train_data[\"binarysentiment\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"binarysentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes with tf-idf and with N-grams </b>\n",
    "\n",
    "78.46% accuracy on binary sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.46\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"binarysentiment\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"binarysentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes with tf-idf and without N-grams </b>\n",
    "\n",
    "Score is 81.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"binarysentiment\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"binarysentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes without tf-idf and with N-grams </b>\n",
    "\n",
    "Score is 83.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"binarysentiment\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"binarysentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Tests on grouped scores </b>  </h1>\n",
    "\n",
    "Here, scores are grouped together to create fewer classes. The \"sentiment\" column is used for training and testing.\n",
    "\n",
    "The groups are as follows: {1,2} , {3,4} , {7,8} , {9,10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and without N-grams </b>\n",
    "\n",
    "58.82% accuracy on the grouped scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothy\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "                             \n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"sentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"sentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and with N-grams </b>\n",
    "\n",
    "67.84% accuracy on the grouped scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.91\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"sentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"sentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and without N-grams </b>\n",
    "\n",
    "Score of 64.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.42\n"
     ]
    }
   ],
   "source": [
    "#SVM WITH TFIDF NO NGRAMS 64.42%\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"sentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"sentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and with N-grams </b>\n",
    "\n",
    "Score of 65.78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothy\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM NO TFIDF WITH NGRAMS 65.78%\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"sentiment\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"sentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes without tf-idf and without N-grams </b>\n",
    "\n",
    "69.38% accuracy on the grouped scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.38\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "                             \n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"sentiment\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"sentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes with tf-idf and with N-grams </b>\n",
    "\n",
    "52.04% accuracy on the grouped scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.04\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"sentiment\"])\n",
    "\n",
    "y_pred= clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"sentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NB with tf-idf and without N-grams </b>\n",
    "\n",
    "Score of 56.43%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.43\n"
     ]
    }
   ],
   "source": [
    "#NB WITH TFIDF NO NGRAMS 56.43%\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"sentiment\"])\n",
    "\n",
    "y_pred= clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"sentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NB without tf-idf with N-grams </b>\n",
    "\n",
    "Score of 94.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.11\n"
     ]
    }
   ],
   "source": [
    "#NB NO TFIDF WITH NGRAMS 94.11%\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"sentiment\"])\n",
    "\n",
    "y_pred= clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"sentiment\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Tests on scores from 1-4 and 7-10 </b>  </h1>\n",
    "\n",
    "This is the hardest category for the model to train and test on, as it has the most classes. The \"score\" column is used for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and without N-grams </b>\n",
    "\n",
    "35.88% accuracy on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothy\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "                             \n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"score\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"score\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and with N-grams </b>\n",
    "\n",
    "45.98% accuracy on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.98\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"score\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"score\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM with tf-idf and without N-grams </b>\n",
    "\n",
    "Score of 42.02%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.02\n"
     ]
    }
   ],
   "source": [
    "#SVM WITH TFIDF NO NGRAMS 42.02%\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text)\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"score\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"score\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM without tf-idf and with N-grams </b>\n",
    "\n",
    "Score of 42.97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.97\n"
     ]
    }
   ],
   "source": [
    "#SVM NO TFIDF WITH NGRAMS 42.97%\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"])    \n",
    "test_features = vectorizer.transform(data[\"review\"])\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, train_data[\"score\"])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "acc = accuracy_score(data[\"score\"], y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes without tf-idf and without N-grams </b>\n",
    "\n",
    "56.25% accuracy on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.25\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text) #This is CountVectorizer, NOT TfidfVectorizer\n",
    "                             \n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"score\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"score\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Naive Bayes with tf-idf and with N-grams </b>\n",
    "\n",
    "28.40 % accuracy on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.42\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"score\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"score\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NB with tf-idf and without N-grams </b>\n",
    "\n",
    "Score of 78.55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB WITH TFIDF NO NGRAMS 78.55%\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"score\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"score\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NB without tf-idf and with N-grams </b>\n",
    "\n",
    "Score of 33.98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB NO TFIDF WITH NGRAMS 33.98%\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=clean_text,\n",
    "                             ngram_range=(1, 2)) #Set here for unigrams and bigrams\n",
    "training_features = vectorizer.fit_transform(train_data[\"review\"].values)\n",
    "test_features = vectorizer.transform(data[\"review\"].values)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(training_features,train_data[\"score\"])\n",
    "\n",
    "y_pred = clf.predict(training_features)\n",
    "\n",
    "acc = accuracy_score(train_data[\"score\"], y_pred, normalize=True)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
